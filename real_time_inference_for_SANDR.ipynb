{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "383c7378-4a46-4875-86cd-2c3a2c481e20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time to focus\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "# --- Secure Key Loading ---\n",
    "# os.getenv(KEY_NAME, DEFAULT_VALUE)\n",
    "API_KEY = os.getenv(\"ALPACA_API_KEY\")\n",
    "SECRET_KEY = os.getenv(\"ALPACA_SECRET_KEY\")\n",
    "\n",
    "if not API_KEY or not SECRET_KEY:\n",
    "    raise ValueError(\"API Keys not found! Set ALPACA_API_KEY and ALPACA_SECRET_KEY in your environment.\")\n",
    "else:\n",
    "    print('time to focus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62942db8-699e-4f3c-bbd3-fea3b9b05784",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5eb4a7-159d-47b8-a56c-581dd150ee95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#REAL-TIME 1: MONITOR PRICES\n",
    "#REAL_TIME 2: CONFIGURE STATIC/DYNAMIC SPLIT AND PREDICT FXN\n",
    "# Add this to the top of your real-time cell (before importing asyncio or alpaca)\n",
    "#!pip install nest-asyncio\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "import asyncio\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import re\n",
    "import time\n",
    "from alpaca.data.live.stock import StockDataStream\n",
    "import os\n",
    "# ==========================================\n",
    "# 1. THE REAL-TIME ENGINE CLASS\n",
    "# ==========================================\n",
    "class TradingModelRealTime:\n",
    "    def __init__(self, model_pkl_path, static_features_csv_path):\n",
    "        self.data = joblib.load(model_pkl_path)\n",
    "        self.model = self.data['model']\n",
    "        self.feature_order = self.data['features']\n",
    "        self.symbol = self.data['symbol']\n",
    "        self.dynamic_map = self._parse_feature_requirements()\n",
    "        \n",
    "        # Load the \"Baseline\" (The last row of your weekly CSV)\n",
    "        full_df = pd.read_csv(static_features_csv_path)\n",
    "        self.baseline_row = full_df.iloc[-1].to_dict()\n",
    "\n",
    "    def _parse_feature_requirements(self):\n",
    "        dynamic_map = []\n",
    "        cl_pattern = r\"change_lag_(\\d+)(\\d+)th_ptile_(.*)\"\n",
    "        zs_pattern = r\"z_score_(\\d+)_(.*)\"\n",
    "        for feat in self.feature_order:\n",
    "            m_cl = re.match(cl_pattern, feat)\n",
    "            m_zs = re.match(zs_pattern, feat)\n",
    "            if m_cl:\n",
    "                lag, ptile, ticker = m_cl.groups()\n",
    "                dynamic_map.append({'feature': feat, 'type': 'cl', 'ticker': ticker,\n",
    "                                  'ancillary': [f'{ptile}th_ptile_lag_{lag}days_{ticker}']})\n",
    "            elif m_zs:\n",
    "                lag, ticker = m_zs.groups()\n",
    "                dynamic_map.append({'feature': feat, 'type': 'zs', 'ticker': ticker,\n",
    "                                  'ancillary': [f'rolling_mean_{lag}_{ticker}', f'rolling_std_{lag}_{ticker}']})\n",
    "        return dynamic_map\n",
    "\n",
    "    def predict(self, live_prices):\n",
    "        spy_price = live_prices.get('SPY')\n",
    "        if not spy_price: return None\n",
    "        \n",
    "        input_vector = {}\n",
    "        # Fill static features\n",
    "        for feat in self.feature_order:\n",
    "            input_vector[feat] = self.baseline_row.get(feat, 0)\n",
    "\n",
    "        # Calculate dynamic features\n",
    "        for item in self.dynamic_map:\n",
    "            ticker = item['ticker']\n",
    "            if ticker in live_prices:\n",
    "                rel_price = live_prices[ticker] / spy_price\n",
    "                if item['type'] == 'cl':\n",
    "                    thresh = self.baseline_row[item['ancillary'][0]]\n",
    "                    input_vector[item['feature']] = (rel_price - thresh) / thresh\n",
    "                elif item['type'] == 'zs':\n",
    "                    mu = self.baseline_row[item['ancillary'][0]]\n",
    "                    sigma = self.baseline_row[item['ancillary'][1]]\n",
    "                    input_vector[item['feature']] = (rel_price - mu) / sigma if sigma != 0 else 0\n",
    "\n",
    "        X = pd.DataFrame([input_vector])[self.feature_order]\n",
    "        return self.model.predict_proba(X)[0][1]\n",
    "\n",
    "# ==========================================\n",
    "# 2. GLOBAL CONFIG & INITIALIZATION\n",
    "# ==========================================\n",
    "import os\n",
    "\n",
    "# --- Secure Key Loading ---\n",
    "# os.getenv(KEY_NAME, DEFAULT_VALUE)\n",
    "API_KEY = os.getenv(\"ALPACA_API_KEY\")\n",
    "SECRET_KEY = os.getenv(\"ALPACA_SECRET_KEY\")\n",
    "MODEL_PATH ='models/champion_model_DIOD_[0.88221709 0.5414673 ].pkl'\n",
    "CSV_PATH = 'feature_presentation_semiconductors.csv'\n",
    "PREDICTION_INTERVAL = 10  # Run prediction every 10 seconds\n",
    "\n",
    "# Global dictionary to store incoming prices\n",
    "live_prices = {}\n",
    "\n",
    "# Initialize Engine\n",
    "engine = TradingModelRealTime(MODEL_PATH, CSV_PATH)\n",
    "\n",
    "# Auto-generate Watchlist from Model Features\n",
    "base_name = os.path.basename(MODEL_PATH) # Gets 'champion_model_DIOD_85.pkl'\n",
    "target_stock = base_name.split('_')[2]\n",
    "watchlist = set(f.split('_')[-1] for f in engine.feature_order)\n",
    "watchlist.update([target_stock, 'SPY'])\n",
    "WATCHLIST = list(watchlist)\n",
    "\n",
    "# ==========================================\n",
    "# 3. ASYNC TASKS\n",
    "# ==========================================\n",
    "async def on_quote_update(data):\n",
    "    \"\"\"Updates the price dictionary as fast as quotes arrive.\"\"\"\n",
    "    if data.bid_price > 0 and data.ask_price > 0:\n",
    "        live_prices[data.symbol] = (data.bid_price + data.ask_price) / 2\n",
    "\n",
    "async def inference_loop():\n",
    "    \"\"\"Calculates predictions on a fixed timer (N seconds).\"\"\"\n",
    "    print(f\"[INFO] Inference loop started (Interval: {PREDICTION_INTERVAL}s)\")\n",
    "    while True:\n",
    "        # 1. Ensure we have SPY and at least some data before predicting\n",
    "        if 'SPY' in live_prices and len(live_prices) > 1:\n",
    "            try:\n",
    "                prob = engine.predict(live_prices)\n",
    "                print(prob)\n",
    "                timestamp = dt.datetime.now().strftime('%H:%M:%S')\n",
    "                print(f\"[{timestamp}] Model: {engine.symbol} | Signal Probability: {prob:.4f}\")\n",
    "                \n",
    "                # Logic for trading:\n",
    "                if prob > 0.85:\n",
    "                    print(f\"*** HIGH CONVICTION SIGNAL DETECTED FOR {engine.symbol} ***\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"[ERROR] Prediction failed: {e}\")\n",
    "        else:\n",
    "            print(f\"[WAIT] Waiting for more data... (Current count: {len(live_prices)}/{len(WATCHLIST)})\")\n",
    "            \n",
    "        await asyncio.sleep(PREDICTION_INTERVAL)\n",
    "\n",
    "async def main():\n",
    "    while True:\n",
    "        inference_task = None\n",
    "        try:\n",
    "            # 1. Start Fresh\n",
    "            stream = StockDataStream(API_KEY, SECRET_KEY)\n",
    "\n",
    "            # 2. Subscribe\n",
    "            for symbol in WATCHLIST:\n",
    "                stream.subscribe_quotes(on_quote_update, symbol)\n",
    "            \n",
    "            print(f\"[START] Attempting connection at {dt.datetime.now()}\")\n",
    "\n",
    "            # 3. Start the Inference Loop as a background task\n",
    "            inference_task = asyncio.create_task(inference_loop())\n",
    "            \n",
    "            # 4. Run the stream (This is the \"main\" blocking call)\n",
    "            # We await this directly. If it fails, it jumps to 'except'\n",
    "            await stream.run()\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[RECONNECT] Error caught in main loop: {e}\")\n",
    "            \n",
    "            # 5. Mandatory Cleanup\n",
    "            if inference_task:\n",
    "                inference_task.cancel()\n",
    "                try:\n",
    "                    await inference_task\n",
    "                except asyncio.CancelledError:\n",
    "                    pass\n",
    "            \n",
    "            print(\"Retrying in 5 seconds...\")\n",
    "            await asyncio.sleep(5)\n",
    "\n",
    "# --- JUPYTER EXECUTION ---\n",
    "# If you are in a notebook, just run this:\n",
    "await main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
